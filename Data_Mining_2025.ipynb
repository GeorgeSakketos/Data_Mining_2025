{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeorgeSakketos/Data_Mining_2025/blob/main/Data_Mining_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-adXMYAFzv-"
      },
      "source": [
        "# **Mounting Google Drive to Collab**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7OhUZHRFzUn"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "csv_folder_path = '/content/drive/My Drive/Data_Mining_CSV'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UmhN5j4xPZm"
      },
      "source": [
        "# **Part 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZ_MfWsM0te9"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jetNqpBL8Li"
      },
      "source": [
        "Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rtgg9HCML61L"
      },
      "outputs": [],
      "source": [
        "from itertools import islice\n",
        "import sys\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "from datasets import load_dataset\n",
        "\n",
        "print('Python version ' + sys.version)\n",
        "print('Pandas version ' + pd.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------- Cleaning Functions -------------------\n",
        "\n",
        "def normalize_price(price):\n",
        "    if isinstance(price, str):\n",
        "        match = re.search(r'[\\d,.]+', price)\n",
        "        if match:\n",
        "            return float(match.group(0).replace(',', ''))\n",
        "    return None\n",
        "\n",
        "def clean_text(text):\n",
        "    if isinstance(text, str):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "        return text.strip()\n",
        "    return ''\n",
        "\n",
        "def flatten_image_struct(example):\n",
        "    images_raw = example.get('images', '[]')\n",
        "    try:\n",
        "        images = json.loads(images_raw) if isinstance(images_raw, str) else images_raw\n",
        "    except json.JSONDecodeError:\n",
        "        images = []\n",
        "    example['image_urls'] = [img.get('hi_res', '') for img in images if isinstance(img, dict)]\n",
        "    return example"
      ],
      "metadata": {
        "id": "QaqLgfeS9sCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_01uHbM5Kf6"
      },
      "source": [
        "# Home and Kitchen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZOGelW6xKvJ"
      },
      "outputs": [],
      "source": [
        "# ------------------- Load and Sample Data -------------------\n",
        "\n",
        "Home_and_Kitchen_review_ds = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_Home_and_Kitchen\", trust_remote_code=True, split=\"full\", streaming=True)\n",
        "Home_and_Kitchen_meta_ds = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_meta_Home_and_Kitchen\", trust_remote_code=True, split=\"full\", streaming=True)\n",
        "\n",
        "# Get set amount of rows\n",
        "hak_rows_to_get = 20000\n",
        "hak_review_sample = list(islice(Home_and_Kitchen_review_ds, hak_rows_to_get))\n",
        "Home_and_Kitchen_meta_ds = Home_and_Kitchen_meta_ds.map(flatten_image_struct)\n",
        "hak_meta_sample = list(islice(Home_and_Kitchen_meta_ds, hak_rows_to_get))\n",
        "pd.set_option('display.max_rows', hak_rows_to_get)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# # Get all rows\n",
        "# hak_review_sample = list(Home_and_Kitchen_review_ds)\n",
        "# Home_and_Kitchen_meta_ds = Home_and_Kitchen_meta_ds.map(flatten_image_struct)\n",
        "# hak_meta_sample = list(Home_and_Kitchen_meta_ds)\n",
        "\n",
        "hak_reviews_df = pd.DataFrame(hak_review_sample)\n",
        "hak_meta_df = pd.DataFrame(hak_meta_sample)\n",
        "\n",
        "# ------------------- Clean Meta Dataset -------------------\n",
        "\n",
        "clean_hak_meta_df = hak_meta_df.copy()\n",
        "\n",
        "meta_cols_to_keep = [\n",
        "    'parent_asin', 'main_category', 'product_title', 'average_rating', 'rating_number',\n",
        "    'description', 'price', 'store', 'details'\n",
        "]\n",
        "clean_hak_meta_df = clean_hak_meta_df.rename(columns={'title': 'product_title'})\n",
        "clean_hak_meta_df = clean_hak_meta_df.loc[:, meta_cols_to_keep]\n",
        "\n",
        "# Drop incomplete entries\n",
        "clean_hak_meta_df = clean_hak_meta_df.dropna(subset=['product_title', 'main_category', 'price']).copy()\n",
        "\n",
        "# Clean 'description'\n",
        "clean_hak_meta_df.loc[:, 'description'] = clean_hak_meta_df['description'].apply(\n",
        "    lambda desc: clean_text(' '.join(desc)) if isinstance(desc, list)\n",
        "    else clean_text(desc) if isinstance(desc, str)\n",
        "    else 'No description available'\n",
        ")\n",
        "\n",
        "# Clean other fields\n",
        "clean_hak_meta_df.loc[:, 'details'] = clean_hak_meta_df['details'].fillna('').astype(str).apply(clean_text)\n",
        "clean_hak_meta_df.loc[:, 'average_rating'] = clean_hak_meta_df['average_rating'].fillna(0).astype(float)\n",
        "clean_hak_meta_df.loc[:, 'rating_number'] = clean_hak_meta_df['rating_number'].fillna(0).astype(int)\n",
        "clean_hak_meta_df.loc[:, 'price'] = clean_hak_meta_df['price'].apply(normalize_price)\n",
        "clean_hak_meta_df = clean_hak_meta_df.dropna(subset=['price']).copy()\n",
        "clean_hak_meta_df.loc[:, 'store'] = clean_hak_meta_df['store'].fillna('Unknown')\n",
        "clean_hak_meta_df.loc[:, 'product_title'] = clean_hak_meta_df['product_title'].apply(clean_text)\n",
        "clean_hak_meta_df.loc[:, 'parent_asin'] = clean_hak_meta_df['parent_asin'].astype(str)\n",
        "\n",
        "clean_hak_meta_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# ------------------- Clean Reviews Dataset -------------------\n",
        "\n",
        "clean_hak_reviews_df = hak_reviews_df.copy()\n",
        "\n",
        "if 'images' in clean_hak_reviews_df.columns:\n",
        "    clean_hak_reviews_df = clean_hak_reviews_df.drop(columns=['images'])\n",
        "\n",
        "clean_hak_reviews_df = clean_hak_reviews_df.dropna(subset=['rating', 'text', 'asin', 'parent_asin']).copy()\n",
        "clean_hak_reviews_df = clean_hak_reviews_df[clean_hak_reviews_df['verified_purchase'] == True].copy()\n",
        "\n",
        "clean_hak_reviews_df.loc[:, 'title'] = clean_hak_reviews_df['title'].fillna('').apply(clean_text)\n",
        "clean_hak_reviews_df.loc[:, 'text'] = clean_hak_reviews_df['text'].apply(clean_text)\n",
        "clean_hak_reviews_df.loc[:, 'helpful_vote'] = clean_hak_reviews_df['helpful_vote'].fillna(0).astype(int)\n",
        "\n",
        "# Convert timestamp from milliseconds to seconds (remove milliseconds)\n",
        "clean_hak_reviews_df.loc[:, 'timestamp'] = (clean_hak_reviews_df['timestamp'].astype('int64') // 1000)\n",
        "converted_timestamps = pd.to_datetime(clean_hak_reviews_df['timestamp'], unit='s', errors='coerce')\n",
        "clean_hak_reviews_df = clean_hak_reviews_df.drop(columns=['timestamp'])\n",
        "clean_hak_reviews_df['timestamp'] = converted_timestamps\n",
        "\n",
        "# Split timestamp into date and time\n",
        "clean_hak_reviews_df.loc[:, 'date'] = clean_hak_reviews_df['timestamp'].dt.date\n",
        "clean_hak_reviews_df.loc[:, 'time'] = clean_hak_reviews_df['timestamp'].dt.strftime('%H:%M:%S')\n",
        "\n",
        "# Drop original timestamp column\n",
        "clean_hak_reviews_df.drop(columns=['timestamp'], inplace=True)\n",
        "\n",
        "clean_hak_reviews_df.loc[:, 'parent_asin'] = clean_hak_reviews_df['parent_asin'].astype(str)\n",
        "clean_hak_reviews_df.rename(columns={'title': 'review_title'}, inplace=True)\n",
        "clean_hak_reviews_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# ------------------- Merge Datasets -------------------\n",
        "\n",
        "clean_hak_merged_df = pd.merge(clean_hak_reviews_df, clean_hak_meta_df, on='parent_asin', how='left')\n",
        "clean_hak_merged_df = clean_hak_merged_df.dropna().reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save to CSV"
      ],
      "metadata": {
        "id": "dTIkZ3vzPlz-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seae6vslrRxS"
      },
      "outputs": [],
      "source": [
        "# Create the CSV file\n",
        "clean_hak_merged_df.to_csv(f\"{csv_folder_path}/Home_and_Kitchen.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3ki1-8oGsSv"
      },
      "source": [
        "Load from CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAVfyKDpGv0x"
      },
      "outputs": [],
      "source": [
        "# Load Gift Cards CSV file\n",
        "home_and_kitchen = pd.read_csv(f\"{csv_folder_path}/Home_and_Kitchen.csv\")\n",
        "\n",
        "# Show file\n",
        "home_and_kitchen.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Automotive"
      ],
      "metadata": {
        "id": "d3hqB4SYTrnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------- Load and Sample Data -------------------\n",
        "\n",
        "Automotive_review_ds = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_Automotive\", trust_remote_code=True, split=\"full\", streaming=True)\n",
        "Automotive_meta_ds = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_meta_Automotive\", trust_remote_code=True, split=\"full\", streaming=True)\n",
        "\n",
        "# Get set amount of rows\n",
        "a_rows_to_get = 20000\n",
        "a_review_sample = list(islice(Automotive_review_ds, a_rows_to_get))\n",
        "Automotive_meta_ds = Automotive_meta_ds.map(flatten_image_struct)\n",
        "a_meta_sample = list(islice(Automotive_meta_ds, a_rows_to_get))\n",
        "pd.set_option('display.max_rows', a_rows_to_get)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# # Get all rows\n",
        "# a_review_sample = list(Automotive_review_ds)\n",
        "# Automotive_meta_ds = Automotive_meta_ds.map(flatten_image_struct)\n",
        "# a_meta_sample = list(Automotive_meta_ds)\n",
        "\n",
        "a_reviews_df = pd.DataFrame(a_review_sample)\n",
        "a_meta_df = pd.DataFrame(a_meta_sample)\n",
        "\n",
        "# ------------------- Clean Meta Dataset -------------------\n",
        "\n",
        "clean_a_meta_df = a_meta_df.copy()\n",
        "\n",
        "meta_cols_to_keep = [\n",
        "    'parent_asin', 'main_category', 'product_title', 'average_rating', 'rating_number',\n",
        "    'description', 'price', 'store', 'details'\n",
        "]\n",
        "clean_a_meta_df = clean_a_meta_df.rename(columns={'title': 'product_title'})\n",
        "clean_a_meta_df = clean_a_meta_df.loc[:, meta_cols_to_keep]\n",
        "\n",
        "# Drop incomplete entries\n",
        "clean_a_meta_df = clean_a_meta_df.dropna(subset=['product_title', 'main_category', 'price']).copy()\n",
        "\n",
        "# Clean 'description'\n",
        "clean_a_meta_df.loc[:, 'description'] = clean_a_meta_df['description'].apply(\n",
        "    lambda desc: clean_text(' '.join(desc)) if isinstance(desc, list)\n",
        "    else clean_text(desc) if isinstance(desc, str)\n",
        "    else 'No description available'\n",
        ")\n",
        "\n",
        "# Clean other fields\n",
        "clean_a_meta_df.loc[:, 'details'] = clean_a_meta_df['details'].fillna('').astype(str).apply(clean_text)\n",
        "clean_a_meta_df.loc[:, 'average_rating'] = clean_a_meta_df['average_rating'].fillna(0).astype(float)\n",
        "clean_a_meta_df.loc[:, 'rating_number'] = clean_a_meta_df['rating_number'].fillna(0).astype(int)\n",
        "clean_a_meta_df.loc[:, 'price'] = clean_a_meta_df['price'].apply(normalize_price)\n",
        "clean_a_meta_df = clean_a_meta_df.dropna(subset=['price']).copy()\n",
        "clean_a_meta_df.loc[:, 'store'] = clean_a_meta_df['store'].fillna('Unknown')\n",
        "clean_a_meta_df.loc[:, 'product_title'] = clean_a_meta_df['product_title'].apply(clean_text)\n",
        "clean_a_meta_df.loc[:, 'parent_asin'] = clean_a_meta_df['parent_asin'].astype(str)\n",
        "\n",
        "clean_a_meta_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# ------------------- Clean Reviews Dataset -------------------\n",
        "\n",
        "clean_a_reviews_df = a_reviews_df.copy()\n",
        "\n",
        "if 'images' in clean_a_reviews_df.columns:\n",
        "    clean_a_reviews_df = clean_a_reviews_df.drop(columns=['images'])\n",
        "\n",
        "clean_a_reviews_df = clean_a_reviews_df.dropna(subset=['rating', 'text', 'asin', 'parent_asin']).copy()\n",
        "clean_a_reviews_df = clean_a_reviews_df[clean_a_reviews_df['verified_purchase'] == True].copy()\n",
        "\n",
        "clean_a_reviews_df.loc[:, 'title'] = clean_a_reviews_df['title'].fillna('').apply(clean_text)\n",
        "clean_a_reviews_df.loc[:, 'text'] = clean_a_reviews_df['text'].apply(clean_text)\n",
        "clean_a_reviews_df.loc[:, 'helpful_vote'] = clean_a_reviews_df['helpful_vote'].fillna(0).astype(int)\n",
        "\n",
        "# Convert timestamp from milliseconds to seconds (remove milliseconds)\n",
        "clean_a_reviews_df.loc[:, 'timestamp'] = (clean_a_reviews_df['timestamp'].astype('int64') // 1000)\n",
        "converted_timestamps = pd.to_datetime(clean_a_reviews_df['timestamp'], unit='s', errors='coerce')\n",
        "clean_a_reviews_df = clean_a_reviews_df.drop(columns=['timestamp'])\n",
        "clean_a_reviews_df['timestamp'] = converted_timestamps\n",
        "\n",
        "# Split timestamp into date and time\n",
        "clean_a_reviews_df.loc[:, 'date'] = clean_a_reviews_df['timestamp'].dt.date\n",
        "clean_a_reviews_df.loc[:, 'time'] = clean_a_reviews_df['timestamp'].dt.strftime('%H:%M:%S')\n",
        "\n",
        "# Drop original timestamp column\n",
        "clean_a_reviews_df.drop(columns=['timestamp'], inplace=True)\n",
        "\n",
        "clean_a_reviews_df.loc[:, 'parent_asin'] = clean_a_reviews_df['parent_asin'].astype(str)\n",
        "clean_a_reviews_df.rename(columns={'title': 'review_title'}, inplace=True)\n",
        "clean_a_reviews_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# ------------------- Merge Datasets -------------------\n",
        "\n",
        "clean_a_merged_df = pd.merge(clean_a_reviews_df, clean_a_meta_df, on='parent_asin', how='left')\n",
        "clean_a_merged_df = clean_a_merged_df.dropna().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "F3FFMHqIT08n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save to CSV"
      ],
      "metadata": {
        "id": "ncj9vGS7UFau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the CSV file\n",
        "clean_a_merged_df.to_csv(f\"{csv_folder_path}/Automotive.csv\", index=False)"
      ],
      "metadata": {
        "id": "qaGKBASCUGY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load from CSV"
      ],
      "metadata": {
        "id": "UQ2wcdjEUGul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Gift Cards CSV file\n",
        "automotive_df = pd.read_csv(f\"{csv_folder_path}/Automotive.csv\")\n",
        "\n",
        "# Show file\n",
        "automotive_df.head()"
      ],
      "metadata": {
        "id": "xeq9_hW4UHml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTAAz5dwMBj6"
      },
      "source": [
        "# Electronics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5Q_emhBNERB"
      },
      "outputs": [],
      "source": [
        "# ------------------- Load and Sample Data -------------------\n",
        "\n",
        "Electronics_review_ds = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_Electronics\", trust_remote_code=True, split=\"full\", streaming=True)\n",
        "Electronics_meta_ds = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_meta_Electronics\", trust_remote_code=True, split=\"full\", streaming=True)\n",
        "\n",
        "# Get set amount of rows\n",
        "e_rows_to_get = 20000\n",
        "e_review_sample = list(islice(Electronics_review_ds, e_rows_to_get))\n",
        "Electronics_meta_ds = Electronics_meta_ds.map(flatten_image_struct)\n",
        "e_meta_sample = list(islice(Electronics_meta_ds, e_rows_to_get))\n",
        "pd.set_option('display.max_rows', e_rows_to_get)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# # Get all rows\n",
        "# e_review_sample = list(Electronics_review_ds)\n",
        "# Electronics_meta_ds = Electronics_meta_ds.map(flatten_image_struct)\n",
        "# e_meta_sample = list(Electronics_meta_ds)\n",
        "\n",
        "e_reviews_df = pd.DataFrame(e_review_sample)\n",
        "e_meta_df = pd.DataFrame(e_meta_sample)\n",
        "\n",
        "# ------------------- Clean Meta Dataset -------------------\n",
        "\n",
        "clean_e_meta_df = e_meta_df.copy()\n",
        "\n",
        "meta_cols_to_keep = [\n",
        "    'parent_asin', 'main_category', 'product_title', 'average_rating', 'rating_number',\n",
        "    'description', 'price', 'store', 'details'\n",
        "]\n",
        "clean_e_meta_df = clean_e_meta_df.rename(columns={'title': 'product_title'})\n",
        "clean_e_meta_df = clean_e_meta_df.loc[:, meta_cols_to_keep]\n",
        "\n",
        "# Drop incomplete entries\n",
        "clean_e_meta_df = clean_e_meta_df.dropna(subset=['product_title', 'main_category', 'price']).copy()\n",
        "\n",
        "# Clean 'description'\n",
        "clean_e_meta_df.loc[:, 'description'] = clean_e_meta_df['description'].apply(\n",
        "    lambda desc: clean_text(' '.join(desc)) if isinstance(desc, list)\n",
        "    else clean_text(desc) if isinstance(desc, str)\n",
        "    else 'No description available'\n",
        ")\n",
        "\n",
        "# Clean other fields\n",
        "clean_e_meta_df.loc[:, 'details'] = clean_e_meta_df['details'].fillna('').astype(str).apply(clean_text)\n",
        "clean_e_meta_df.loc[:, 'average_rating'] = clean_e_meta_df['average_rating'].fillna(0).astype(float)\n",
        "clean_e_meta_df.loc[:, 'rating_number'] = clean_e_meta_df['rating_number'].fillna(0).astype(int)\n",
        "clean_e_meta_df.loc[:, 'price'] = clean_e_meta_df['price'].apply(normalize_price)\n",
        "clean_e_meta_df = clean_e_meta_df.dropna(subset=['price']).copy()\n",
        "clean_e_meta_df.loc[:, 'store'] = clean_e_meta_df['store'].fillna('Unknown')\n",
        "clean_e_meta_df.loc[:, 'product_title'] = clean_e_meta_df['product_title'].apply(clean_text)\n",
        "clean_e_meta_df.loc[:, 'parent_asin'] = clean_e_meta_df['parent_asin'].astype(str)\n",
        "\n",
        "clean_e_meta_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# ------------------- Clean Reviews Dataset -------------------\n",
        "\n",
        "clean_e_reviews_df = e_reviews_df.copy()\n",
        "\n",
        "if 'images' in clean_e_reviews_df.columns:\n",
        "    clean_e_reviews_df = clean_e_reviews_df.drop(columns=['images'])\n",
        "\n",
        "clean_e_reviews_df = clean_e_reviews_df.dropna(subset=['rating', 'text', 'asin', 'parent_asin']).copy()\n",
        "clean_e_reviews_df = clean_e_reviews_df[clean_e_reviews_df['verified_purchase'] == True].copy()\n",
        "\n",
        "clean_e_reviews_df.loc[:, 'title'] = clean_e_reviews_df['title'].fillna('').apply(clean_text)\n",
        "clean_e_reviews_df.loc[:, 'text'] = clean_e_reviews_df['text'].apply(clean_text)\n",
        "clean_e_reviews_df.loc[:, 'helpful_vote'] = clean_e_reviews_df['helpful_vote'].fillna(0).astype(int)\n",
        "\n",
        "# Convert timestamp from milliseconds to seconds (remove milliseconds)\n",
        "clean_e_reviews_df.loc[:, 'timestamp'] = (clean_e_reviews_df['timestamp'].astype('int64') // 1000)\n",
        "converted_timestamps = pd.to_datetime(clean_e_reviews_df['timestamp'], unit='s', errors='coerce')\n",
        "clean_e_reviews_df = clean_e_reviews_df.drop(columns=['timestamp'])\n",
        "clean_e_reviews_df['timestamp'] = converted_timestamps\n",
        "\n",
        "# Split timestamp into date and time\n",
        "clean_e_reviews_df.loc[:, 'date'] = clean_e_reviews_df['timestamp'].dt.date\n",
        "clean_e_reviews_df.loc[:, 'time'] = clean_e_reviews_df['timestamp'].dt.strftime('%H:%M:%S')\n",
        "\n",
        "# Drop original timestamp column\n",
        "clean_e_reviews_df.drop(columns=['timestamp'], inplace=True)\n",
        "\n",
        "clean_e_reviews_df.loc[:, 'parent_asin'] = clean_e_reviews_df['parent_asin'].astype(str)\n",
        "clean_e_reviews_df.rename(columns={'title': 'review_title'}, inplace=True)\n",
        "clean_e_reviews_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# ------------------- Merge Datasets -------------------\n",
        "\n",
        "clean_e_merged_df = pd.merge(clean_e_reviews_df, clean_e_meta_df, on='parent_asin', how='left')\n",
        "clean_e_merged_df = clean_e_merged_df.dropna().reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save to CSV"
      ],
      "metadata": {
        "id": "pTe_yqDNPsz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the CSV file\n",
        "clean_e_merged_df.to_csv(f\"{csv_folder_path}/Electronics.csv\", index=False)"
      ],
      "metadata": {
        "id": "hrxDYU4-PtyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load from CSV"
      ],
      "metadata": {
        "id": "ZX_9GDO3Pug-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Gift Cards CSV file\n",
        "electronics_df = pd.read_csv(f\"{csv_folder_path}/Electronics.csv\")\n",
        "\n",
        "# Show file\n",
        "electronics_df.head()"
      ],
      "metadata": {
        "id": "xqBQy_JmP1qH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YsqaDAzj-BH"
      },
      "source": [
        "# Health and Household"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eQbJJQfkBe3"
      },
      "outputs": [],
      "source": [
        "# ------------------- Load and Sample Data -------------------\n",
        "\n",
        "Health_and_Household_review_ds = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_Health_and_Household\", trust_remote_code=True, split=\"full\", streaming=True)\n",
        "Health_and_Household_meta_ds = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_meta_Health_and_Household\", trust_remote_code=True, split=\"full\", streaming=True)\n",
        "\n",
        "# Get set amount of rows\n",
        "hah_rows_to_get = 20000\n",
        "hah_review_sample = list(islice(Health_and_Household_review_ds, hah_rows_to_get))\n",
        "Health_and_Household_meta_ds = Health_and_Household_meta_ds.map(flatten_image_struct)\n",
        "hah_meta_sample = list(islice(Health_and_Household_meta_ds, hah_rows_to_get))\n",
        "pd.set_option('display.max_rows', hah_rows_to_get)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# # Get all rows\n",
        "# hah_review_sample = list(Health_and_Household_review_ds)\n",
        "# Health_and_Household_meta_ds = Health_and_Household_meta_ds.map(flatten_image_struct)\n",
        "# hah_meta_sample = list(Health_and_Household_meta_ds)\n",
        "\n",
        "hah_reviews_df = pd.DataFrame(hah_review_sample)\n",
        "hah_meta_df = pd.DataFrame(hah_meta_sample)\n",
        "\n",
        "# ------------------- Clean Meta Dataset -------------------\n",
        "\n",
        "clean_hah_meta_df = hah_meta_df.copy()\n",
        "\n",
        "meta_cols_to_keep = [\n",
        "    'parent_asin', 'main_category', 'product_title', 'average_rating', 'rating_number',\n",
        "    'description', 'price', 'store', 'details'\n",
        "]\n",
        "clean_hah_meta_df = clean_hah_meta_df.rename(columns={'title': 'product_title'})\n",
        "clean_hah_meta_df = clean_hah_meta_df.loc[:, meta_cols_to_keep]\n",
        "\n",
        "# Drop incomplete entries\n",
        "clean_hah_meta_df = clean_hah_meta_df.dropna(subset=['product_title', 'main_category', 'price']).copy()\n",
        "\n",
        "# Clean 'description'\n",
        "clean_hah_meta_df.loc[:, 'description'] = clean_hah_meta_df['description'].apply(\n",
        "    lambda desc: clean_text(' '.join(desc)) if isinstance(desc, list)\n",
        "    else clean_text(desc) if isinstance(desc, str)\n",
        "    else 'No description available'\n",
        ")\n",
        "\n",
        "# Clean other fields\n",
        "clean_hah_meta_df.loc[:, 'details'] = clean_hah_meta_df['details'].fillna('').astype(str).apply(clean_text)\n",
        "clean_hah_meta_df.loc[:, 'average_rating'] = clean_hah_meta_df['average_rating'].fillna(0).astype(float)\n",
        "clean_hah_meta_df.loc[:, 'rating_number'] = clean_hah_meta_df['rating_number'].fillna(0).astype(int)\n",
        "clean_hah_meta_df.loc[:, 'price'] = clean_hah_meta_df['price'].apply(normalize_price)\n",
        "clean_hah_meta_df = clean_hah_meta_df.dropna(subset=['price']).copy()\n",
        "clean_hah_meta_df.loc[:, 'store'] = clean_hah_meta_df['store'].fillna('Unknown')\n",
        "clean_hah_meta_df.loc[:, 'product_title'] = clean_hah_meta_df['product_title'].apply(clean_text)\n",
        "clean_hah_meta_df.loc[:, 'parent_asin'] = clean_hah_meta_df['parent_asin'].astype(str)\n",
        "\n",
        "clean_hah_meta_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# ------------------- Clean Reviews Dataset -------------------\n",
        "\n",
        "clean_hah_reviews_df = hah_reviews_df.copy()\n",
        "\n",
        "if 'images' in clean_hah_reviews_df.columns:\n",
        "    clean_hah_reviews_df = clean_hah_reviews_df.drop(columns=['images'])\n",
        "\n",
        "clean_hah_reviews_df = clean_hah_reviews_df.dropna(subset=['rating', 'text', 'asin', 'parent_asin']).copy()\n",
        "clean_hah_reviews_df = clean_hah_reviews_df[clean_hah_reviews_df['verified_purchase'] == True].copy()\n",
        "\n",
        "clean_hah_reviews_df.loc[:, 'title'] = clean_hah_reviews_df['title'].fillna('').apply(clean_text)\n",
        "clean_hah_reviews_df.loc[:, 'text'] = clean_hah_reviews_df['text'].apply(clean_text)\n",
        "clean_hah_reviews_df.loc[:, 'helpful_vote'] = clean_hah_reviews_df['helpful_vote'].fillna(0).astype(int)\n",
        "\n",
        "# Convert timestamp from milliseconds to seconds (remove milliseconds)\n",
        "clean_hah_reviews_df.loc[:, 'timestamp'] = (clean_hah_reviews_df['timestamp'].astype('int64') // 1000)\n",
        "converted_timestamps = pd.to_datetime(clean_hah_reviews_df['timestamp'], unit='s', errors='coerce')\n",
        "clean_hah_reviews_df = clean_hah_reviews_df.drop(columns=['timestamp'])\n",
        "clean_hah_reviews_df['timestamp'] = converted_timestamps\n",
        "\n",
        "# Split timestamp into date and time\n",
        "clean_hah_reviews_df.loc[:, 'date'] = clean_hah_reviews_df['timestamp'].dt.date\n",
        "clean_hah_reviews_df.loc[:, 'time'] = clean_hah_reviews_df['timestamp'].dt.strftime('%H:%M:%S')\n",
        "\n",
        "# Drop original timestamp column\n",
        "clean_hah_reviews_df.drop(columns=['timestamp'], inplace=True)\n",
        "\n",
        "clean_hah_reviews_df.loc[:, 'parent_asin'] = clean_hah_reviews_df['parent_asin'].astype(str)\n",
        "clean_hah_reviews_df.rename(columns={'title': 'review_title'}, inplace=True)\n",
        "clean_hah_reviews_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# ------------------- Merge Datasets -------------------\n",
        "\n",
        "clean_hah_merged_df = pd.merge(clean_hah_reviews_df, clean_hah_meta_df, on='parent_asin', how='left')\n",
        "clean_hah_merged_df = clean_hah_merged_df.dropna().reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save to CSV"
      ],
      "metadata": {
        "id": "UIAlHjskSccg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the CSV file\n",
        "clean_hah_merged_df.to_csv(f\"{csv_folder_path}/Health_and_Household.csv\", index=False)"
      ],
      "metadata": {
        "id": "0ah7SFUKR9co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load from CSV"
      ],
      "metadata": {
        "id": "9B7yxQeWSj2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Gift Cards CSV file\n",
        "health_and_household_df = pd.read_csv(f\"{csv_folder_path}/Health_and_Household.csv\")\n",
        "\n",
        "# Show file\n",
        "health_and_household_df.head()"
      ],
      "metadata": {
        "id": "iAQPWqtLSmXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9w-BonhjflB"
      },
      "source": [
        "# Software"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4iZYhVYjgzQ"
      },
      "outputs": [],
      "source": [
        "# ------------------- Load and Sample Data -------------------\n",
        "\n",
        "Software_review_ds = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_Software\", trust_remote_code=True, split=\"full\", streaming=True)\n",
        "Software_meta_ds = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_meta_Software\", trust_remote_code=True, split=\"full\", streaming=True)\n",
        "\n",
        "# Get set amount of rows\n",
        "s_rows_to_get = 20000\n",
        "s_review_sample = list(islice(Software_review_ds, s_rows_to_get))\n",
        "Software_meta_ds = Software_meta_ds.map(flatten_image_struct)\n",
        "s_meta_sample = list(islice(Software_meta_ds, s_rows_to_get))\n",
        "pd.set_option('display.max_rows', s_rows_to_get)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# # Get all rows\n",
        "# s_review_sample = list(Software_review_ds)\n",
        "# Software_meta_ds = Software_meta_ds.map(flatten_image_struct)\n",
        "# s_meta_sample = list(Software_meta_ds)\n",
        "\n",
        "s_reviews_df = pd.DataFrame(s_review_sample)\n",
        "s_meta_df = pd.DataFrame(s_meta_sample)\n",
        "\n",
        "# ------------------- Clean Meta Dataset -------------------\n",
        "\n",
        "clean_s_meta_df = s_meta_df.copy()\n",
        "\n",
        "meta_cols_to_keep = [\n",
        "    'parent_asin', 'main_category', 'product_title', 'average_rating', 'rating_number',\n",
        "    'description', 'price', 'store', 'details'\n",
        "]\n",
        "clean_s_meta_df = clean_s_meta_df.rename(columns={'title': 'product_title'})\n",
        "clean_s_meta_df = clean_s_meta_df.loc[:, meta_cols_to_keep]\n",
        "\n",
        "# Drop incomplete entries\n",
        "clean_s_meta_df = clean_s_meta_df.dropna(subset=['product_title', 'main_category', 'price']).copy()\n",
        "\n",
        "# Clean 'description'\n",
        "clean_s_meta_df.loc[:, 'description'] = clean_s_meta_df['description'].apply(\n",
        "    lambda desc: clean_text(' '.join(desc)) if isinstance(desc, list)\n",
        "    else clean_text(desc) if isinstance(desc, str)\n",
        "    else 'No description available'\n",
        ")\n",
        "\n",
        "# Clean other fields\n",
        "clean_s_meta_df.loc[:, 'details'] = clean_s_meta_df['details'].fillna('').astype(str).apply(clean_text)\n",
        "clean_s_meta_df.loc[:, 'average_rating'] = clean_s_meta_df['average_rating'].fillna(0).astype(float)\n",
        "clean_s_meta_df.loc[:, 'rating_number'] = clean_s_meta_df['rating_number'].fillna(0).astype(int)\n",
        "clean_s_meta_df.loc[:, 'price'] = clean_s_meta_df['price'].apply(normalize_price)\n",
        "clean_s_meta_df = clean_s_meta_df.dropna(subset=['price']).copy()\n",
        "clean_s_meta_df.loc[:, 'store'] = clean_s_meta_df['store'].fillna('Unknown')\n",
        "clean_s_meta_df.loc[:, 'product_title'] = clean_s_meta_df['product_title'].apply(clean_text)\n",
        "clean_s_meta_df.loc[:, 'parent_asin'] = clean_s_meta_df['parent_asin'].astype(str)\n",
        "\n",
        "clean_s_meta_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# ------------------- Clean Reviews Dataset -------------------\n",
        "\n",
        "clean_s_reviews_df = s_reviews_df.copy()\n",
        "\n",
        "if 'images' in clean_s_reviews_df.columns:\n",
        "    clean_s_reviews_df = clean_s_reviews_df.drop(columns=['images'])\n",
        "\n",
        "clean_s_reviews_df = clean_s_reviews_df.dropna(subset=['rating', 'text', 'asin', 'parent_asin']).copy()\n",
        "clean_s_reviews_df = clean_s_reviews_df[clean_s_reviews_df['verified_purchase'] == True].copy()\n",
        "\n",
        "clean_s_reviews_df.loc[:, 'title'] = clean_s_reviews_df['title'].fillna('').apply(clean_text)\n",
        "clean_s_reviews_df.loc[:, 'text'] = clean_s_reviews_df['text'].apply(clean_text)\n",
        "clean_s_reviews_df.loc[:, 'helpful_vote'] = clean_s_reviews_df['helpful_vote'].fillna(0).astype(int)\n",
        "\n",
        "# Convert timestamp from milliseconds to seconds (remove milliseconds)\n",
        "clean_s_reviews_df.loc[:, 'timestamp'] = (clean_s_reviews_df['timestamp'].astype('int64') // 1000)\n",
        "converted_timestamps = pd.to_datetime(clean_s_reviews_df['timestamp'], unit='s', errors='coerce')\n",
        "clean_s_reviews_df = clean_s_reviews_df.drop(columns=['timestamp'])\n",
        "clean_s_reviews_df['timestamp'] = converted_timestamps\n",
        "\n",
        "# Split timestamp into date and time\n",
        "clean_s_reviews_df.loc[:, 'date'] = clean_s_reviews_df['timestamp'].dt.date\n",
        "clean_s_reviews_df.loc[:, 'time'] = clean_s_reviews_df['timestamp'].dt.strftime('%H:%M:%S')\n",
        "\n",
        "# Drop original timestamp column\n",
        "clean_s_reviews_df.drop(columns=['timestamp'], inplace=True)\n",
        "\n",
        "clean_s_reviews_df.loc[:, 'parent_asin'] = clean_s_reviews_df['parent_asin'].astype(str)\n",
        "clean_s_reviews_df.rename(columns={'title': 'review_title'}, inplace=True)\n",
        "clean_s_reviews_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# ------------------- Merge Datasets -------------------\n",
        "\n",
        "clean_s_merged_df = pd.merge(clean_s_reviews_df, clean_s_meta_df, on='parent_asin', how='left')\n",
        "clean_s_merged_df = clean_s_merged_df.dropna().reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save to CSV"
      ],
      "metadata": {
        "id": "Oerz67BQRjSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the CSV file\n",
        "clean_s_merged_df.to_csv(f\"{csv_folder_path}/Software.csv\", index=False)"
      ],
      "metadata": {
        "id": "YwEiZi1zQs6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load from CSV"
      ],
      "metadata": {
        "id": "eewClaNaRrtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Gift Cards CSV file\n",
        "software_df = pd.read_csv(f\"{csv_folder_path}/Software.csv\")\n",
        "\n",
        "# Show file\n",
        "software_df.head()"
      ],
      "metadata": {
        "id": "ur8N9DxURs1Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Q_01uHbM5Kf6",
        "d3hqB4SYTrnq",
        "zTAAz5dwMBj6",
        "1YsqaDAzj-BH"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}